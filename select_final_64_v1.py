"""
Round 3: Stoichiometric Reduction
Reduces ~6,600 R2-classified candidates to the Final 64 ISA.

Quotas:
  SUB (Anchors/Registers):     12
  PRO (Engines/Op-Codes):      20
  REL (Bridges/ALU):           12
  MOD (Qualifiers/Flags):      10
  STR (Frames/Bus/Control):    10

Reduction steps:
  1. Isotope Purge ‚Äî kill semantic duplicates
  2. Constructibility Check ‚Äî kill compounds
  3. Cultural Decontamination ‚Äî kill high-culture, low-physics
  4. Stoichiometric Fill ‚Äî top-N by score per category
"""

import json
from collections import defaultdict
from dataclasses import dataclass, field
from typing import Dict, List, Set, Tuple, Optional

# ============================================================================
# QUOTAS (The ISA Blueprint)
# ============================================================================

QUOTAS = {
    "SUB": 12,  # Registers ‚Äî ontological anchors
    "PRO": 20,  # Op-Codes ‚Äî transformation engines
    "REL": 12,  # ALU ‚Äî logic connectives
    "MOD": 10,  # Flags ‚Äî quality scalars
    "STR": 10,  # Bus/Control ‚Äî spatial frames
}

# ============================================================================
# ISOTOPE GROUPS ‚Äî Semantic duplicates (keep first, kill rest)
# ============================================================================

# Format: list of sets. Within each set, first element is the survivor.
# Sorted by: simplicity (stroke count), universality, Unicode stability.
ISOTOPE_GROUPS = [
    # Void/Nothing/Emptiness
    ["Á©∫", "ÁÑ°", "Êó†", "Ê©Ü", "Ëôõ"],
    # Truth
    ["Áúü", "Áúû"],
    # Transform/Change
    ["Âåñ", "ËÆä", "Âèò"],
    # Create/Generate
    ["Áîü", "Ââµ"],
    # Do/Act/Make
    ["ÁÇ∫", "Áà≤", "‰∏∫"],
    # Think/Thought
    ["ÊÄù", "ÊÉ≥"],
    # Way/Path/Principle
    ["ÈÅì", "Âôµ"],
    # Between/Inter
    ["Èñì", "Èó¥"],
    # Law/Pattern
    ["Ê≥ï", "Âæã"],
    # Spirit/Divine
    ["Á•û", "Èùà"],
    # Beauty/Good
    ["ÂñÑ", "Áæé"],
    # Heart/Mind
    ["ÂøÉ", "ÊÑè"],
    # Not/Negation
    ["‰∏ç", "Èùû"],
    # One/Unity
    ["‰∏Ä", "Â£π"],
    # Great/Large
    ["Â§ß", "Â§™"],
    # Fire
    ["ÁÅ´", "ÁÇÅ"],
    # Observe/See
    ["ËßÇ", "Áèæ", "Áé∞"],
    # Han/Chinese (cultural, but track for decontam)
    ["Êº¢", "Ê±â"],
    # Brain
    ["ËÑë", "ËÖ¶"],
]

# ============================================================================
# CULTURAL DECONTAMINATION ‚Äî High culture, low physics utility
# ============================================================================

CULTURAL_KILLS = {
    "Êº¢", "Ê±â",     # "Han Chinese" ‚Äî ethnic, not universal
    "Á±≥",           # "Rice" ‚Äî agricultural, not atomic
    "Áæä",           # "Sheep" ‚Äî livestock, not primitive
    "Â∏ù",           # "Emperor" ‚Äî political hierarchy
    "Áéã",           # "King" ‚Äî political hierarchy
    "È≥≥",           # "Phoenix" ‚Äî mythological
    "Èπø",           # "Deer" ‚Äî animal, not primitive
    "È£Ø",           # "Rice/meal" ‚Äî food
    "Èæç",           # "Dragon" ‚Äî mythological
    "È≤≤",           # "Kun fish" ‚Äî mythological
    "È•ï",           # "Taotie" ‚Äî mythological glutton
    "ÊÜ≤",           # "Constitution" ‚Äî legal document
    "Êøü",           # "Aid/Ford" ‚Äî too specific
    "Èüã",           # Surname-heavy
    "È≥¥",           # "Cry of bird" ‚Äî too specific
    "È∂º",           # "Lovebirds" ‚Äî too specific
    "Áôå",           # "Cancer" ‚Äî medical, not ontological
    "Áóõ",           # "Pain" ‚Äî sensation, constructible from body+damage
    "Ëõã",           # "Egg" ‚Äî too specific
}

# ============================================================================
# CONSTRUCTIBILITY KILLS ‚Äî Compounds expressible from primes
# ============================================================================

# These can be built from simpler atoms in the final language
CONSTRUCTIBLE_KILLS = {
    "ÊÖß": "ÂøÉ+Êòé (wisdom = mind + clarity)",
    "Âì≤": "ÂøÉ+ÁêÜ (philosophy = mind + principle)",
    "Ë™†": "Ë®Ä+Áúü (sincerity = speech + truth)",
    "Âæ∑": "ÂøÉ+Ë°å (virtue = mind + action)",
    "ËÅñ": "‰∫∫+Á•û (holy = person + divine)",
    "ÊôÆ": "Â§ß+Áî® (universal = great + use)",
    "ÈÆÆ": "Êñ∞+Áâ© (fresh = new + matter)",
    "Á∞°": "‰∏Ä+ÁêÜ (simple = one + principle)",
    "ÊΩõ": "Ê∞¥+‰∏ã (latent = water + below)",
    "ÊæÑ": "Ê∞¥+Ê∏Ö (clear = water + pure)",
    "Èáç": "Â§ß+Âäõ (heavy = great + force)",
    "Ê®Ç": "ÂøÉ+ÂñÑ (joy = mind + good)",
    "È°û": "Áõ∏+Âêå (classify = mutual + same)",
    "Á™Æ": "Á©∫+Áõ° (exhaust = void + end)",
    "ËΩâ": "Âåñ+Âõû (rotate = transform + return)",
    "ÊøÄ": "Ê∞¥+Âäõ (excite = water + force)",
    "Á∂≤": "Áµ≤+‰∫§ (net = thread + cross)",
    "È°å": "Ë®Ä+Âïè (topic = speech + question)",
    "Ë´ñ": "Ë®Ä+ÁêÜ (theory = speech + principle)",
    "ÁßØ": "Âúü+Áîü (accumulate = earth + grow)",
    "Áæ©": "ÂñÑ+ÁêÜ (justice = good + principle)",
}


# ============================================================================
# LOAD DATA
# ============================================================================

def load_merged_data():
    """Load R1 scores + R2 assay, merge, return sorted list."""
    scores = {}
    with open('data/round_1.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            chunk = json.loads(line)
            for g, s in chunk['scores'].items():
                scores[g] = s

    assay = {}
    with open('data/round_2_assay.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            chunk = json.loads(line)
            for a in chunk['assays']:
                assay[a['glyph']] = a

    merged = []
    for g, a in assay.items():
        if g in scores:
            merged.append({**a, 'score': scores[g]})

    # Sort by score descending, then by glyph for stability
    merged.sort(key=lambda x: (-x['score'], x['glyph']))
    return merged


# ============================================================================
# REDUCTION ENGINE
# ============================================================================

def reduce(merged: list) -> dict:
    """
    Execute the 4-step reduction algorithm.
    Returns dict of category -> list of selected glyphs.
    """

    # Build lookup
    by_glyph = {m['glyph']: m for m in merged}
    alive = set(m['glyph'] for m in merged)
    kill_log = []

    def kill(glyph, reason):
        if glyph in alive:
            alive.discard(glyph)
            kill_log.append((glyph, reason))

    # ‚îÄ‚îÄ Step 1: Isotope Purge ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("\nüß™ STEP 1: Isotope Purge")
    for group in ISOTOPE_GROUPS:
        # Keep first that's alive, kill rest
        survivor = None
        for g in group:
            if g in alive:
                if survivor is None:
                    survivor = g
                else:
                    kill(g, f"isotope of {survivor}")
        if survivor:
            killed = [g for g in group[1:] if g != survivor and (g, f"isotope of {survivor}") in kill_log]
            if killed:
                print(f"  {survivor} survives, killed: {''.join(killed)}")

    # ‚îÄ‚îÄ Step 2: Constructibility Check ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("\nüî® STEP 2: Constructibility Check")
    for g, reason in CONSTRUCTIBLE_KILLS.items():
        if g in alive:
            kill(g, f"constructible: {reason}")
            print(f"  ‚úó {g} = {reason}")

    # ‚îÄ‚îÄ Step 3: Cultural Decontamination ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("\nüßπ STEP 3: Cultural Decontamination")
    for g in CULTURAL_KILLS:
        if g in alive:
            kill(g, "cultural/specific, not atomic")
            print(f"  ‚úó {g}")

    # ‚îÄ‚îÄ Step 4: Stoichiometric Fill ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("\n‚öóÔ∏è  STEP 4: Stoichiometric Fill")

    # Bucket survivors by category, score-ordered
    buckets = defaultdict(list)
    for m in merged:
        if m['glyph'] in alive:
            buckets[m['category']].append(m)

    selected = {}
    for cat in ["SUB", "PRO", "REL", "MOD", "STR"]:
        quota = QUOTAS[cat]
        candidates = buckets[cat]
        picked = candidates[:quota]
        selected[cat] = picked
        overflow = len(candidates) - quota
        print(f"  {cat}: {len(candidates)} candidates -> picked {len(picked)}/{quota}" +
              (f" (dropped {overflow})" if overflow > 0 else f" (UNDERFILL by {quota - len(picked)})" if len(picked) < quota else ""))

    return selected, kill_log


# ============================================================================
# DISPLAY
# ============================================================================

def display_final_64(selected: dict):
    """Pretty-print the final 64."""
    print(f"\n{'='*72}")
    print(f"  THE 64-GLYPH INSTRUCTION SET ARCHITECTURE")
    print(f"{'='*72}")

    total = 0
    all_glyphs = []

    for cat, label, analog in [
        ("SUB", "SUBSTANCE (Anchors)", "Registers"),
        ("PRO", "PROCESS (Engines)", "Op-Codes"),
        ("REL", "RELATION (Bridges)", "ALU"),
        ("MOD", "MODIFIER (Qualifiers)", "Flags"),
        ("STR", "STRUCTURE (Frames)", "Bus/Control"),
    ]:
        items = selected[cat]
        total += len(items)
        quota = QUOTAS[cat]

        print(f"\n  ‚îå‚îÄ {label} [{len(items)}/{quota}] ‚îÄ‚îÄ {analog}")
        print(f"  ‚îÇ")

        for m in items:
            g = m['glyph']
            a = m['arity']
            d = m['direction']
            f = m['failure']
            s = m['score']
            # Direction symbol
            dir_sym = {"L": "‚Üê", "R": "‚Üí", "S": "‚Üî", "O": "‚óé"}.get(d, "?")
            # Failure symbol
            f_sym = {"SAT": "‚óè", "STALL": "‚óê", "BOOM": "‚ú¶", "NULL": "‚óã"}.get(f, "?")
            print(f"  ‚îÇ  {g}  A:{a} {dir_sym} {f_sym}  (score {s})")
            all_glyphs.append(g)

        print(f"  ‚îî{'‚îÄ'*40}")

    print(f"\n  TOTAL: {total}/64")
    print(f"\n  THE SET: {''.join(all_glyphs)}")

    return all_glyphs


def display_kill_summary(kill_log):
    """Show what was killed and why."""
    if not kill_log:
        return
    reasons = defaultdict(list)
    for g, r in kill_log:
        reasons[r.split(':')[0] if ':' in r else r].append(g)

    print(f"\n{'='*72}")
    print(f"  KILL LOG ({len(kill_log)} eliminated)")
    print(f"{'='*72}")
    for reason, glyphs in sorted(reasons.items()):
        print(f"  {reason}: {''.join(glyphs[:20])}" +
              (f" +{len(glyphs)-20} more" if len(glyphs) > 20 else ""))


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("‚öóÔ∏è  Round 3: Stoichiometric Reduction")
    print(f"Target: 64 glyphs ({' + '.join(f'{v} {k}' for k, v in QUOTAS.items())})")

    # Load
    merged = load_merged_data()
    print(f"Loaded {len(merged)} classified candidates")

    # Reduce
    selected, kill_log = reduce(merged)

    # Display
    all_glyphs = display_final_64(selected)
    display_kill_summary(kill_log)

    # Save
    with open('data/final_64.json', 'w', encoding='utf-8') as f:
        output = {
            "quotas": QUOTAS,
            "total": len(all_glyphs),
            "glyphs": all_glyphs,
            "details": {cat: items for cat, items in selected.items()},
        }
        json.dump(output, f, ensure_ascii=False, indent=2)
    print(f"\n‚úì Saved to data/final_64.json")

    with open('data/final_64.txt', 'w', encoding='utf-8') as f:
        f.write(''.join(all_glyphs))
    print(f"‚úì Saved to data/final_64.txt")


if __name__ == "__main__":
    main()
